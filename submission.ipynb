{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load Training Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random, os, time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xrr\\AppData\\Local\\Temp\\ipykernel_18640\\2727693222.py:6: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  rz_dict = {'bilinear': Image.BILINEAR,\n",
      "C:\\Users\\xrr\\AppData\\Local\\Temp\\ipykernel_18640\\2727693222.py:7: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': Image.BICUBIC,\n",
      "C:\\Users\\xrr\\AppData\\Local\\Temp\\ipykernel_18640\\2727693222.py:8: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': Image.LANCZOS,\n",
      "C:\\Users\\xrr\\AppData\\Local\\Temp\\ipykernel_18640\\2727693222.py:9: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': Image.NEAREST}\n"
     ]
    }
   ],
   "source": [
    "def sample_discrete(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    return random.choice(s)\n",
    "\n",
    "rz_dict = {'bilinear': Image.BILINEAR,\n",
    "           'bicubic': Image.BICUBIC,\n",
    "           'lanczos': Image.LANCZOS,\n",
    "           'nearest': Image.NEAREST}\n",
    "\n",
    "def custom_resize(img, opt):\n",
    "    interp = sample_discrete(opt.rz_interp)\n",
    "    return TF.resize(img, opt.loadSize, interpolation=rz_dict[interp])\n",
    "\n",
    "def dataset_folder(opt, root):\n",
    "    if opt.isTrain:\n",
    "        crop_func = transforms.RandomCrop(opt.cropSize)\n",
    "    elif opt.no_crop:\n",
    "        crop_func = transforms.Lambda(lambda img: img)\n",
    "    else:\n",
    "        crop_func = transforms.CenterCrop(opt.cropSize)\n",
    "\n",
    "    if opt.isTrain and not opt.no_flip:\n",
    "        flip_func = transforms.RandomHorizontalFlip()\n",
    "    else:\n",
    "        flip_func = transforms.Lambda(lambda img: img)\n",
    "    if not opt.isTrain and opt.no_resize:\n",
    "        rz_func = transforms.Lambda(lambda img: img)\n",
    "    else:\n",
    "        rz_func = transforms.Lambda(lambda img: custom_resize(img, opt))\n",
    "\n",
    "    dset = datasets.ImageFolder(\n",
    "            root,\n",
    "            transforms.Compose([\n",
    "                rz_func,\n",
    "                transforms.Lambda(lambda img: Image.fromarray(np.array(img))),\n",
    "                crop_func,\n",
    "                flip_func,\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]))\n",
    "    return dset\n",
    "\n",
    "def get_dataset(opt):\n",
    "    dset_lst = []\n",
    "    for cls in opt.classes:\n",
    "        root = opt.dataroot + '/' + cls\n",
    "        dset = dataset_folder(opt, root)\n",
    "        dset_lst.append(dset)\n",
    "    return torch.utils.data.ConcatDataset(dset_lst)\n",
    "\n",
    "def create_dataloader(opt):\n",
    "    shuffle = not opt.serial_batches if (opt.isTrain and not opt.class_bal) else False\n",
    "    dataset = get_dataset(opt)\n",
    "    # sampler = get_bal_sampler(dataset) if opt.class_bal else None\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=opt.batch_size,\n",
    "                                              shuffle=shuffle,\n",
    "                                              #sampler=sampler,\n",
    "                                              )\n",
    "    return data_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "model_urls = {\n",
    "    # 'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    # 'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    # 'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    # 'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module): # 单独写出来没啥用，最好整合至trainer内\n",
    "    def __init__(self, opt):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.total_steps = 0\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "        self.device = torch.device('cuda:{}'.format(opt.gpu_ids[0])) if opt.gpu_ids else torch.device('cpu')\n",
    "\n",
    "    def save_networks(self, epoch):\n",
    "        save_filename = 'model_epoch_%s.pth' % epoch\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "\n",
    "        # serialize model and optimizer to dict\n",
    "        state_dict = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'total_steps' : self.total_steps,\n",
    "        }\n",
    "\n",
    "        torch.save(state_dict, save_path)\n",
    "\n",
    "    # load models from the disk\n",
    "    def load_networks(self, epoch):\n",
    "        load_filename = 'model_epoch_%s.pth' % epoch\n",
    "        load_path = os.path.join(self.save_dir, load_filename)\n",
    "\n",
    "        print('loading the model from %s' % load_path)\n",
    "        # if you are using PyTorch newer than 0.4 (e.g., built from\n",
    "        # GitHub source), you can remove str() on self.device\n",
    "        state_dict = torch.load(load_path, map_location=self.device)\n",
    "        if hasattr(state_dict, '_metadata'):\n",
    "            del state_dict._metadata\n",
    "\n",
    "        self.model.load_state_dict(state_dict['model'])\n",
    "        self.total_steps = state_dict['total_steps']\n",
    "\n",
    "        if self.isTrain and not self.opt.new_optim:\n",
    "            self.optimizer.load_state_dict(state_dict['optimizer'])\n",
    "            ### move optimizer state to GPU\n",
    "            for state in self.optimizer.state.values():\n",
    "                for k, v in state.items():\n",
    "                    if torch.is_tensor(v):\n",
    "                        state[k] = v.to(self.device)\n",
    "\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = self.opt.lr\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            self.forward()\n",
    "\n",
    "class Trainer(BaseModel):\n",
    "    def name(self):\n",
    "        return 'Trainer'\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        super(Trainer, self).__init__(opt)\n",
    "\n",
    "        if self.isTrain and not opt.continue_train:\n",
    "            self.model = resnet50(pretrained=True)\n",
    "            self.model.fc = nn.Linear(2048, 1)\n",
    "            torch.nn.init.normal_(self.model.fc.weight.data, 0.0, opt.init_gain)\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.model = resnet50(num_classes=1)\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "            # initialize optimizers\n",
    "            if opt.optim == 'adam':\n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                                  lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            elif opt.optim == 'sgd':\n",
    "                self.optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                                 lr=opt.lr, momentum=0.0, weight_decay=0)\n",
    "            else:\n",
    "                raise ValueError(\"optim should be [adam, sgd]\")\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.load_networks(opt.epoch)\n",
    "        self.model.to(opt.gpu_ids[0])\n",
    "\n",
    "\n",
    "    def adjust_learning_rate(self, min_lr=1e-6):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] /= 10.\n",
    "            if param_group['lr'] < min_lr:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input[0].to(self.device)\n",
    "        self.label = input[1].to(self.device).float()\n",
    "\n",
    "    def forward(self):\n",
    "        self.output = self.model(self.input)\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.loss_fn(self.output.squeeze(1), self.label)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "        self.loss = self.loss_fn(self.output.squeeze(1), self.label)\n",
    "        self.optimizer.zero_grad()\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Early Stopping Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=1, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.score_max = -np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "        elif score < self.best_score - self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, score, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({self.score_max:.6f} --> {score:.6f}).  Saving model ...')\n",
    "        model.save_networks('best')\n",
    "        self.score_max = score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parser Settings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def mkdirs(paths):\n",
    "    if isinstance(paths, list) and not isinstance(paths, str):\n",
    "        for path in paths:\n",
    "            mkdir(path)\n",
    "    else:\n",
    "        mkdir(paths)\n",
    "\n",
    "class BaseOptions():\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, parser):\n",
    "        parser.add_argument('--mode', default='binary')\n",
    "        parser.add_argument('--arch', type=str, default='res50', help='architecture for binary classification')\n",
    "\n",
    "        # data augmentation\n",
    "        parser.add_argument('--rz_interp', default='bilinear')\n",
    "        parser.add_argument('--blur_prob', type=float, default=0)\n",
    "        parser.add_argument('--blur_sig', default='0.5')\n",
    "        parser.add_argument('--jpg_prob', type=float, default=0)\n",
    "        parser.add_argument('--jpg_method', default='cv2')\n",
    "        parser.add_argument('--jpg_qual', default='75')\n",
    "\n",
    "        parser.add_argument('--dataroot', default='./dataset/', help='path to images (should have subfolders trainA, trainB, valA, valB, etc)')\n",
    "        parser.add_argument('--classes', default='', help='image classes to train on')\n",
    "        parser.add_argument('--class_bal', action='store_true')\n",
    "        parser.add_argument('--batch_size', type=int, default=64, help='input batch size')\n",
    "        parser.add_argument('--loadSize', type=int, default=256, help='scale images to this size')\n",
    "        parser.add_argument('--cropSize', type=int, default=224, help='then crop to this size')\n",
    "        parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "        parser.add_argument('--name', type=str, default='experiment_name', help='name of the experiment. It decides where to store samples and models')\n",
    "        parser.add_argument('--epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n",
    "        parser.add_argument('--num_threads', default=4, type=int, help='# threads for loading data')\n",
    "        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n",
    "        parser.add_argument('--serial_batches', action='store_true', help='if true, takes images in order to make batches, otherwise takes them randomly')\n",
    "        parser.add_argument('--resize_or_crop', type=str, default='scale_and_crop', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop|none]')\n",
    "        parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data augmentation')\n",
    "        parser.add_argument('--init_type', type=str, default='normal', help='network initialization [normal|xavier|kaiming|orthogonal]')\n",
    "        parser.add_argument('--init_gain', type=float, default=0.02, help='scaling factor for normal, xavier and orthogonal.')\n",
    "        parser.add_argument('--suffix', default='', type=str, help='customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{loadSize}')\n",
    "        self.initialized = True\n",
    "        return parser\n",
    "\n",
    "    def gather_options(self, args):\n",
    "        # initialize parser with basic options\n",
    "        if not self.initialized:\n",
    "            parser = argparse.ArgumentParser(\n",
    "                formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "            parser = self.initialize(parser)\n",
    "\n",
    "        # get the basic options\n",
    "        self.parser = parser\n",
    "\n",
    "        return parser.parse_args(args)\n",
    "\n",
    "    def print_options(self, opt):\n",
    "        message = ''\n",
    "        message += '----------------- Options ---------------\\n'\n",
    "        for k, v in sorted(vars(opt).items()):\n",
    "            comment = ''\n",
    "            default = self.parser.get_default(k)\n",
    "            if v != default:\n",
    "                comment = '\\t[default: %s]' % str(default)\n",
    "            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "        message += '----------------- End -------------------'\n",
    "        print(message)\n",
    "\n",
    "        # save to the disk\n",
    "        expr_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "        mkdirs(expr_dir)\n",
    "        file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "        with open(file_name, 'wt') as opt_file:\n",
    "            opt_file.write(message)\n",
    "            opt_file.write('\\n')\n",
    "\n",
    "    def parse(self, print_options=True, args=None):\n",
    "\n",
    "        opt = self.gather_options(args)\n",
    "        opt.isTrain = self.isTrain   # train or test\n",
    "\n",
    "        # process opt.suffix\n",
    "        if opt.suffix:\n",
    "            suffix = ('_' + opt.suffix.format(**vars(opt))) if opt.suffix != '' else ''\n",
    "            opt.name = opt.name + suffix\n",
    "\n",
    "        if print_options:\n",
    "            self.print_options(opt)\n",
    "\n",
    "        # set gpu ids\n",
    "        str_ids = opt.gpu_ids.split(',')\n",
    "        opt.gpu_ids = []\n",
    "        for str_id in str_ids:\n",
    "            id = int(str_id)\n",
    "            if id >= 0:\n",
    "                opt.gpu_ids.append(id)\n",
    "        if len(opt.gpu_ids) > 0:\n",
    "            torch.cuda.set_device(opt.gpu_ids[0])\n",
    "\n",
    "        # additional\n",
    "        opt.classes = opt.classes.split(',')\n",
    "        opt.rz_interp = opt.rz_interp.split(',')\n",
    "        opt.blur_sig = [float(s) for s in opt.blur_sig.split(',')]\n",
    "        opt.jpg_method = opt.jpg_method.split(',')\n",
    "        opt.jpg_qual = [int(s) for s in opt.jpg_qual.split(',')]\n",
    "        if len(opt.jpg_qual) == 2:\n",
    "            opt.jpg_qual = list(range(opt.jpg_qual[0], opt.jpg_qual[1] + 1))\n",
    "        elif len(opt.jpg_qual) > 2:\n",
    "            raise ValueError(\"Shouldn't have more than 2 values for --jpg_qual.\")\n",
    "\n",
    "        self.opt = opt\n",
    "        return self.opt\n",
    "\n",
    "class TrainOptions(BaseOptions):\n",
    "    def initialize(self, parser):\n",
    "        parser = BaseOptions.initialize(self, parser)\n",
    "        parser.add_argument('--earlystop_epoch', type=int, default=5)\n",
    "        parser.add_argument('--data_aug', action='store_true', help='if specified, perform additional data augmentation (photometric, blurring, jpegging)')\n",
    "        parser.add_argument('--optim', type=str, default='adam', help='optim to use [sgd, adam]')\n",
    "        parser.add_argument('--new_optim', action='store_true', help='new optimizer instead of loading the optim state')\n",
    "        parser.add_argument('--loss_freq', type=int, default=400, help='frequency of showing loss on tensorboard')\n",
    "        parser.add_argument('--save_latest_freq', type=int, default=2000, help='frequency of saving the latest results')\n",
    "        parser.add_argument('--save_epoch_freq', type=int, default=20, help='frequency of saving checkpoints at the end of epochs')\n",
    "        parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "        parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n",
    "        parser.add_argument('--last_epoch', type=int, default=-1, help='starting epoch count for scheduler intialization')\n",
    "        parser.add_argument('--train_split', type=str, default='train', help='train, val, test, etc')\n",
    "        parser.add_argument('--val_split', type=str, default='val', help='train, val, test, etc')\n",
    "        parser.add_argument('--niter', type=int, default=10000, help='# of iter at starting learning rate')\n",
    "        parser.add_argument('--beta1', type=float, default=0.9, help='momentum term of adam')\n",
    "        parser.add_argument('--lr', type=float, default=0.0001, help='initial learning rate for adam')\n",
    "\n",
    "        self.isTrain = True\n",
    "        return parser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training & Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "global_args = [\n",
    "    \"--batch_size\", \"32\", # default=64\n",
    "    \"--dataroot\", \"./dataset\",\n",
    "    \"--name\", \"cs4487_proj_submission\",\n",
    "    \"--init_type\", \"kaiming\", #default=\"normal\"\n",
    "    \"--niter\", \"100\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, accuracy_score\n",
    "\n",
    "def get_val_opt(args=None):\n",
    "    val_opt = TrainOptions().parse(print_options=False, args=args)\n",
    "    val_opt.dataroot = '{}/{}/'.format(val_opt.dataroot, val_opt.val_split)\n",
    "    val_opt.isTrain = False\n",
    "    val_opt.no_resize = False\n",
    "    val_opt.no_crop = False\n",
    "    val_opt.serial_batches = True\n",
    "    val_opt.jpg_method = ['pil']\n",
    "    if len(val_opt.blur_sig) == 2:\n",
    "        b_sig = val_opt.blur_sig\n",
    "        val_opt.blur_sig = [(b_sig[0] + b_sig[1]) / 2]\n",
    "    if len(val_opt.jpg_qual) != 1:\n",
    "        j_qual = val_opt.jpg_qual\n",
    "        val_opt.jpg_qual = [int((j_qual[0] + j_qual[-1]) / 2)]\n",
    "\n",
    "    return val_opt\n",
    "\n",
    "def validate(model, opt):\n",
    "    data_loader = create_dataloader(opt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_true, y_pred = [], []\n",
    "        for img, label in data_loader:\n",
    "            in_tens = img.cuda()\n",
    "            y_pred.extend(model(in_tens).sigmoid().flatten().tolist())\n",
    "            y_true.extend(label.flatten().tolist())\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    r_acc = accuracy_score(y_true[y_true==0], y_pred[y_true==0] > 0.5)\n",
    "    f_acc = accuracy_score(y_true[y_true==1], y_pred[y_true==1] > 0.5)\n",
    "    acc = accuracy_score(y_true, y_pred > 0.5)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    return acc, ap, r_acc, f_acc, y_true, y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                     arch: res50                         \n",
      "               batch_size: 32                            \t[default: 64]\n",
      "                    beta1: 0.9                           \n",
      "                blur_prob: 0                             \n",
      "                 blur_sig: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                class_bal: False                         \n",
      "                  classes:                               \n",
      "           continue_train: False                         \n",
      "                 cropSize: 224                           \n",
      "                 data_aug: False                         \n",
      "                 dataroot: ./dataset                     \t[default: ./dataset/]\n",
      "          earlystop_epoch: 5                             \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: kaiming                       \t[default: normal]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "               jpg_method: cv2                           \n",
      "                 jpg_prob: 0                             \n",
      "                 jpg_qual: 75                            \n",
      "               last_epoch: -1                            \n",
      "                 loadSize: 256                           \n",
      "                loss_freq: 400                           \n",
      "                       lr: 0.0001                        \n",
      "                     mode: binary                        \n",
      "                     name: cs4487_proj_submission        \t[default: experiment_name]\n",
      "                new_optim: False                         \n",
      "                    niter: 100                           \t[default: 10000]\n",
      "                  no_flip: False                         \n",
      "              num_threads: 4                             \n",
      "                    optim: adam                          \n",
      "           resize_or_crop: scale_and_crop                \n",
      "                rz_interp: bilinear                      \n",
      "          save_epoch_freq: 20                            \n",
      "         save_latest_freq: 2000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "              train_split: train                         \n",
      "                val_split: val                           \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions().parse(args=global_args)\n",
    "opt.dataroot = '{}/{}/'.format(opt.dataroot, opt.train_split)\n",
    "val_opt = get_val_opt(args=global_args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training images = 300\n"
     ]
    }
   ],
   "source": [
    "data_loader = create_dataloader(opt)\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = Trainer(opt)\n",
    "early_stopping = EarlyStopping(patience=opt.earlystop_epoch, delta=-0.001, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 0, iters 300\n",
      "(Val @ epoch 0) acc: 0.8566666666666667; ap: 0.974889655969347\n",
      "Validation accuracy increased (-inf --> 0.856667).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [03:46<6:13:56, 226.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.47407254576683044 at step: 400\n",
      "(Val @ epoch 1) acc: 0.9091666666666667; ap: 0.9847207825542317\n",
      "Validation accuracy increased (0.856667 --> 0.909167).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [07:28<6:05:15, 223.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18703503906726837 at step: 800\n",
      "(Val @ epoch 2) acc: 0.9241666666666667; ap: 0.9869375099477796\n",
      "Validation accuracy increased (0.909167 --> 0.924167).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [11:21<6:09:00, 228.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0716029554605484 at step: 1200\n",
      "(Val @ epoch 3) acc: 0.93; ap: 0.9924426903917953\n",
      "Validation accuracy increased (0.924167 --> 0.930000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [15:36<6:21:36, 238.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 4) acc: 0.9516666666666667; ap: 0.9938250419909224\n",
      "Validation accuracy increased (0.930000 --> 0.951667).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [19:24<6:12:02, 234.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15895625948905945 at step: 1600\n",
      "(Val @ epoch 5) acc: 0.96; ap: 0.9951543222430911\n",
      "Validation accuracy increased (0.951667 --> 0.960000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [23:00<5:57:35, 228.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.051036935299634933 at step: 2000\n",
      "saving the latest model cs4487_proj_submission (epoch 6, model.total_steps 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [26:36<5:47:49, 224.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 6) acc: 0.9375; ap: 0.9926094515087042\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [29:52<6:36:50, 256.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [13], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39mtotal_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     11\u001B[0m epoch_iter \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39mbatch_size\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m model\u001B[38;5;241m.\u001B[39moptimize_parameters()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mtotal_steps \u001B[38;5;241m%\u001B[39m opt\u001B[38;5;241m.\u001B[39mloss_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn [5], line 96\u001B[0m, in \u001B[0;36mTrainer.set_input\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_input\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for epoch in tqdm(range(opt.niter)): # 100\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        model.total_steps += 1\n",
    "        epoch_iter += opt.batch_size\n",
    "\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if model.total_steps % opt.loss_freq == 0:\n",
    "            print(\"Train loss: {} at step: {}\".format(model.loss, model.total_steps))\n",
    "\n",
    "        if model.total_steps % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model %s (epoch %d, model.total_steps %d)' %\n",
    "                  (opt.name, epoch, model.total_steps))\n",
    "            model.save_networks('latest')\n",
    "\n",
    "        # print(\"Iter time: %d sec\" % (time.time()-iter_data_time))\n",
    "        # iter_data_time = time.time()\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\n",
    "              (epoch, model.total_steps))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    acc, ap = validate(model.model, val_opt)[:2]\n",
    "    print(\"(Val @ epoch {}) acc: {}; ap: {}\".format(epoch, acc, ap))\n",
    "\n",
    "    early_stopping(acc, model)\n",
    "    if early_stopping.early_stop:\n",
    "        cont_train = model.adjust_learning_rate()\n",
    "        if cont_train:\n",
    "            print(\"Learning rate dropped by 10, continue training...\")\n",
    "            early_stopping = EarlyStopping(patience=opt.earlystop_epoch, delta=-0.002, verbose=True)\n",
    "        else:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "    model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
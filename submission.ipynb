{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load Training Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random, os, time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, roc_auc_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruixu33\\AppData\\Local\\Temp\\ipykernel_22368\\2727693222.py:6: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  rz_dict = {'bilinear': Image.BILINEAR,\n",
      "C:\\Users\\ruixu33\\AppData\\Local\\Temp\\ipykernel_22368\\2727693222.py:7: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': Image.BICUBIC,\n",
      "C:\\Users\\ruixu33\\AppData\\Local\\Temp\\ipykernel_22368\\2727693222.py:8: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': Image.LANCZOS,\n",
      "C:\\Users\\ruixu33\\AppData\\Local\\Temp\\ipykernel_22368\\2727693222.py:9: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': Image.NEAREST}\n"
     ]
    }
   ],
   "source": [
    "def sample_discrete(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    return random.choice(s)\n",
    "\n",
    "rz_dict = {'bilinear': Image.BILINEAR,\n",
    "           'bicubic': Image.BICUBIC,\n",
    "           'lanczos': Image.LANCZOS,\n",
    "           'nearest': Image.NEAREST}\n",
    "\n",
    "def custom_resize(img, opt):\n",
    "    interp = sample_discrete(opt.rz_interp)\n",
    "    return TF.resize(img, opt.loadSize, interpolation=rz_dict[interp])\n",
    "\n",
    "def dataset_folder(opt, root):\n",
    "    if opt.isTrain:\n",
    "        crop_func = transforms.RandomCrop(opt.cropSize)\n",
    "    elif opt.no_crop:\n",
    "        crop_func = transforms.Lambda(lambda img: img)\n",
    "    else:\n",
    "        crop_func = transforms.CenterCrop(opt.cropSize)\n",
    "\n",
    "    if opt.isTrain and not opt.no_flip:\n",
    "        flip_func = transforms.RandomHorizontalFlip()\n",
    "    else:\n",
    "        flip_func = transforms.Lambda(lambda img: img)\n",
    "    if not opt.isTrain and opt.no_resize:\n",
    "        rz_func = transforms.Lambda(lambda img: img)\n",
    "    else:\n",
    "        rz_func = transforms.Lambda(lambda img: custom_resize(img, opt))\n",
    "\n",
    "    dset = datasets.ImageFolder(\n",
    "            root,\n",
    "            transforms.Compose([\n",
    "                rz_func,\n",
    "                transforms.Lambda(lambda img: Image.fromarray(np.array(img))),\n",
    "                crop_func,\n",
    "                flip_func,\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]))\n",
    "    return dset\n",
    "\n",
    "def get_dataset(opt):\n",
    "    dset_lst = []\n",
    "    for cls in opt.classes:\n",
    "        root = opt.dataroot + '/' + cls\n",
    "        dset = dataset_folder(opt, root)\n",
    "        dset_lst.append(dset)\n",
    "    return torch.utils.data.ConcatDataset(dset_lst)\n",
    "\n",
    "def create_dataloader(opt):\n",
    "    shuffle = not opt.serial_batches if (opt.isTrain and not opt.class_bal) else False\n",
    "    dataset = get_dataset(opt)\n",
    "    # sampler = get_bal_sampler(dataset) if opt.class_bal else None\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=opt.batch_size,\n",
    "                                              shuffle=shuffle,\n",
    "                                              #sampler=sampler,\n",
    "                                              )\n",
    "    return data_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "model_urls = {\n",
    "    # 'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    # 'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    # 'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    # 'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module): # 单独写出来没啥用，最好整合至trainer内\n",
    "    def __init__(self, opt):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.total_steps = 0\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "        self.device = torch.device('cuda:{}'.format(opt.gpu_ids[0])) if opt.gpu_ids else torch.device('cpu')\n",
    "\n",
    "    def save_networks(self, epoch):\n",
    "        save_filename = 'model_epoch_%s.pth' % epoch\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "\n",
    "        # serialize model and optimizer to dict\n",
    "        state_dict = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'total_steps' : self.total_steps,\n",
    "        }\n",
    "\n",
    "        torch.save(state_dict, save_path)\n",
    "\n",
    "    # load models from the disk\n",
    "    def load_networks(self, epoch):\n",
    "        load_filename = 'model_epoch_%s.pth' % epoch\n",
    "        load_path = os.path.join(self.save_dir, load_filename)\n",
    "\n",
    "        print('loading the model from %s' % load_path)\n",
    "        # if you are using PyTorch newer than 0.4 (e.g., built from\n",
    "        # GitHub source), you can remove str() on self.device\n",
    "        state_dict = torch.load(load_path, map_location=self.device)\n",
    "        if hasattr(state_dict, '_metadata'):\n",
    "            del state_dict._metadata\n",
    "\n",
    "        self.model.load_state_dict(state_dict['model'])\n",
    "        self.total_steps = state_dict['total_steps']\n",
    "\n",
    "        if self.isTrain and not self.opt.new_optim:\n",
    "            self.optimizer.load_state_dict(state_dict['optimizer'])\n",
    "            ### move optimizer state to GPU\n",
    "            for state in self.optimizer.state.values():\n",
    "                for k, v in state.items():\n",
    "                    if torch.is_tensor(v):\n",
    "                        state[k] = v.to(self.device)\n",
    "\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = self.opt.lr\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            self.forward()\n",
    "\n",
    "class Trainer(BaseModel):\n",
    "    def name(self):\n",
    "        return 'Trainer'\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        super(Trainer, self).__init__(opt)\n",
    "\n",
    "        if self.isTrain and not opt.continue_train:\n",
    "            self.model = resnet50(pretrained=True)\n",
    "            self.model.fc = nn.Linear(2048, 1)\n",
    "            torch.nn.init.normal_(self.model.fc.weight.data, 0.0, opt.init_gain)\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.model = resnet50(num_classes=1)\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "            # initialize optimizers\n",
    "            if opt.optim == 'adam':\n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                                  lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            elif opt.optim == 'sgd':\n",
    "                self.optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                                 lr=opt.lr, momentum=0.0, weight_decay=0)\n",
    "            else:\n",
    "                raise ValueError(\"optim should be [adam, sgd]\")\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.load_networks(opt.epoch)\n",
    "        self.model.to(opt.gpu_ids[0])\n",
    "\n",
    "\n",
    "    def adjust_learning_rate(self, min_lr=1e-6):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] /= 10.\n",
    "            if param_group['lr'] < min_lr:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input[0].to(self.device)\n",
    "        self.label = input[1].to(self.device).float()\n",
    "\n",
    "    def forward(self):\n",
    "        self.output = self.model(self.input)\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.loss_fn(self.output.squeeze(1), self.label)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "        self.loss = self.loss_fn(self.output.squeeze(1), self.label)\n",
    "        self.optimizer.zero_grad()\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Early Stopping Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=1, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.score_max = -np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "        elif score < self.best_score - self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, score, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({self.score_max:.6f} --> {score:.6f}).  Saving model ...')\n",
    "        model.save_networks('best')\n",
    "        self.score_max = score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parser Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def mkdirs(paths):\n",
    "    if isinstance(paths, list) and not isinstance(paths, str):\n",
    "        for path in paths:\n",
    "            mkdir(path)\n",
    "    else:\n",
    "        mkdir(paths)\n",
    "\n",
    "class BaseOptions():\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, parser):\n",
    "        parser.add_argument('--mode', default='binary')\n",
    "        parser.add_argument('--arch', type=str, default='res50', help='architecture for binary classification')\n",
    "\n",
    "        # data augmentation\n",
    "        parser.add_argument('--rz_interp', default='bilinear')\n",
    "        parser.add_argument('--blur_prob', type=float, default=0)\n",
    "        parser.add_argument('--blur_sig', default='0.5')\n",
    "        parser.add_argument('--jpg_prob', type=float, default=0)\n",
    "        parser.add_argument('--jpg_method', default='cv2')\n",
    "        parser.add_argument('--jpg_qual', default='75')\n",
    "\n",
    "        parser.add_argument('--dataroot', default='./dataset/', help='path to images (should have subfolders trainA, trainB, valA, valB, etc)')\n",
    "        parser.add_argument('--classes', default='', help='image classes to train on')\n",
    "        parser.add_argument('--class_bal', action='store_true')\n",
    "        parser.add_argument('--batch_size', type=int, default=64, help='input batch size')\n",
    "        parser.add_argument('--loadSize', type=int, default=256, help='scale images to this size')\n",
    "        parser.add_argument('--cropSize', type=int, default=224, help='then crop to this size')\n",
    "        parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "        parser.add_argument('--name', type=str, default='experiment_name', help='name of the experiment. It decides where to store samples and models')\n",
    "        parser.add_argument('--epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n",
    "        parser.add_argument('--num_threads', default=4, type=int, help='# threads for loading data')\n",
    "        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n",
    "        parser.add_argument('--serial_batches', action='store_true', help='if true, takes images in order to make batches, otherwise takes them randomly')\n",
    "        parser.add_argument('--resize_or_crop', type=str, default='scale_and_crop', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop|none]')\n",
    "        parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data augmentation')\n",
    "        parser.add_argument('--init_type', type=str, default='normal', help='network initialization [normal|xavier|kaiming|orthogonal]')\n",
    "        parser.add_argument('--init_gain', type=float, default=0.02, help='scaling factor for normal, xavier and orthogonal.')\n",
    "        parser.add_argument('--suffix', default='', type=str, help='customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{loadSize}')\n",
    "        self.initialized = True\n",
    "        return parser\n",
    "\n",
    "    def gather_options(self, args):\n",
    "        # initialize parser with basic options\n",
    "        if not self.initialized:\n",
    "            parser = argparse.ArgumentParser(\n",
    "                formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "            parser = self.initialize(parser)\n",
    "\n",
    "        # get the basic options\n",
    "        self.parser = parser\n",
    "\n",
    "        return parser.parse_args(args)\n",
    "\n",
    "    def print_options(self, opt):\n",
    "        message = ''\n",
    "        message += '----------------- Options ---------------\\n'\n",
    "        for k, v in sorted(vars(opt).items()):\n",
    "            comment = ''\n",
    "            default = self.parser.get_default(k)\n",
    "            if v != default:\n",
    "                comment = '\\t[default: %s]' % str(default)\n",
    "            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "        message += '----------------- End -------------------'\n",
    "        print(message)\n",
    "\n",
    "        # save to the disk\n",
    "        expr_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "        mkdirs(expr_dir)\n",
    "        file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "        with open(file_name, 'wt') as opt_file:\n",
    "            opt_file.write(message)\n",
    "            opt_file.write('\\n')\n",
    "\n",
    "    def parse(self, print_options=True, args=None):\n",
    "\n",
    "        opt = self.gather_options(args)\n",
    "        opt.isTrain = self.isTrain   # train or test\n",
    "\n",
    "        # process opt.suffix\n",
    "        if opt.suffix:\n",
    "            suffix = ('_' + opt.suffix.format(**vars(opt))) if opt.suffix != '' else ''\n",
    "            opt.name = opt.name + suffix\n",
    "\n",
    "        if print_options:\n",
    "            self.print_options(opt)\n",
    "\n",
    "        # set gpu ids\n",
    "        str_ids = opt.gpu_ids.split(',')\n",
    "        opt.gpu_ids = []\n",
    "        for str_id in str_ids:\n",
    "            id = int(str_id)\n",
    "            if id >= 0:\n",
    "                opt.gpu_ids.append(id)\n",
    "        if len(opt.gpu_ids) > 0:\n",
    "            torch.cuda.set_device(opt.gpu_ids[0])\n",
    "\n",
    "        # additional\n",
    "        opt.classes = opt.classes.split(',')\n",
    "        opt.rz_interp = opt.rz_interp.split(',')\n",
    "        opt.blur_sig = [float(s) for s in opt.blur_sig.split(',')]\n",
    "        opt.jpg_method = opt.jpg_method.split(',')\n",
    "        opt.jpg_qual = [int(s) for s in opt.jpg_qual.split(',')]\n",
    "        if len(opt.jpg_qual) == 2:\n",
    "            opt.jpg_qual = list(range(opt.jpg_qual[0], opt.jpg_qual[1] + 1))\n",
    "        elif len(opt.jpg_qual) > 2:\n",
    "            raise ValueError(\"Shouldn't have more than 2 values for --jpg_qual.\")\n",
    "\n",
    "        self.opt = opt\n",
    "        return self.opt\n",
    "\n",
    "class TrainOptions(BaseOptions):\n",
    "    def initialize(self, parser):\n",
    "        parser = BaseOptions.initialize(self, parser)\n",
    "        parser.add_argument('--earlystop_epoch', type=int, default=5)\n",
    "        parser.add_argument('--data_aug', action='store_true', help='if specified, perform additional data augmentation (photometric, blurring, jpegging)')\n",
    "        parser.add_argument('--optim', type=str, default='adam', help='optim to use [sgd, adam]')\n",
    "        parser.add_argument('--new_optim', action='store_true', help='new optimizer instead of loading the optim state')\n",
    "        parser.add_argument('--loss_freq', type=int, default=400, help='frequency of showing loss on tensorboard')\n",
    "        parser.add_argument('--save_latest_freq', type=int, default=2000, help='frequency of saving the latest results')\n",
    "        parser.add_argument('--save_epoch_freq', type=int, default=20, help='frequency of saving checkpoints at the end of epochs')\n",
    "        parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "        parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n",
    "        parser.add_argument('--last_epoch', type=int, default=-1, help='starting epoch count for scheduler intialization')\n",
    "        parser.add_argument('--train_split', type=str, default='train', help='train, val, test, etc')\n",
    "        parser.add_argument('--val_split', type=str, default='val', help='train, val, test, etc')\n",
    "        parser.add_argument('--niter', type=int, default=10000, help='# of iter at starting learning rate')\n",
    "        parser.add_argument('--beta1', type=float, default=0.9, help='momentum term of adam')\n",
    "        parser.add_argument('--lr', type=float, default=0.0001, help='initial learning rate for adam')\n",
    "\n",
    "        self.isTrain = True\n",
    "        return parser"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training & Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "global_args = [\n",
    "    \"--batch_size\", \"32\", # default=64\n",
    "    \"--dataroot\", \"./dataset\",\n",
    "    \"--name\", \"cs4487_proj_submission\",\n",
    "    \"--init_type\", \"kaiming\", #default=\"normal\"\n",
    "    \"--niter\", \"100\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_val_opt(args=None):\n",
    "    val_opt = TrainOptions().parse(print_options=False, args=args)\n",
    "    val_opt.dataroot = '{}/{}/'.format(val_opt.dataroot, val_opt.val_split)\n",
    "    val_opt.isTrain = False\n",
    "    val_opt.no_resize = False\n",
    "    val_opt.no_crop = False\n",
    "    val_opt.serial_batches = True\n",
    "    val_opt.jpg_method = ['pil']\n",
    "    if len(val_opt.blur_sig) == 2:\n",
    "        b_sig = val_opt.blur_sig\n",
    "        val_opt.blur_sig = [(b_sig[0] + b_sig[1]) / 2]\n",
    "    if len(val_opt.jpg_qual) != 1:\n",
    "        j_qual = val_opt.jpg_qual\n",
    "        val_opt.jpg_qual = [int((j_qual[0] + j_qual[-1]) / 2)]\n",
    "\n",
    "    return val_opt\n",
    "\n",
    "def validate(model, opt):\n",
    "    data_loader = create_dataloader(opt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_true, y_pred = [], []\n",
    "        for img, label in data_loader:\n",
    "            in_tens = img.cuda()\n",
    "            y_pred.extend(model(in_tens).sigmoid().flatten().tolist())\n",
    "            y_true.extend(label.flatten().tolist())\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    r_acc = accuracy_score(y_true[y_true==0], y_pred[y_true==0] > 0.5)\n",
    "    f_acc = accuracy_score(y_true[y_true==1], y_pred[y_true==1] > 0.5)\n",
    "    acc = accuracy_score(y_true, y_pred > 0.5)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    return acc, ap, r_acc, f_acc, y_true, y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                     arch: res50                         \n",
      "               batch_size: 32                            \t[default: 64]\n",
      "                    beta1: 0.9                           \n",
      "                blur_prob: 0                             \n",
      "                 blur_sig: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                class_bal: False                         \n",
      "                  classes:                               \n",
      "           continue_train: False                         \n",
      "                 cropSize: 224                           \n",
      "                 data_aug: False                         \n",
      "                 dataroot: ./dataset                     \t[default: ./dataset/]\n",
      "          earlystop_epoch: 5                             \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: kaiming                       \t[default: normal]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "               jpg_method: cv2                           \n",
      "                 jpg_prob: 0                             \n",
      "                 jpg_qual: 75                            \n",
      "               last_epoch: -1                            \n",
      "                 loadSize: 256                           \n",
      "                loss_freq: 400                           \n",
      "                       lr: 0.0001                        \n",
      "                     mode: binary                        \n",
      "                     name: cs4487_proj_submission        \t[default: experiment_name]\n",
      "                new_optim: False                         \n",
      "                    niter: 100                           \t[default: 10000]\n",
      "                  no_flip: False                         \n",
      "              num_threads: 4                             \n",
      "                    optim: adam                          \n",
      "           resize_or_crop: scale_and_crop                \n",
      "                rz_interp: bilinear                      \n",
      "          save_epoch_freq: 20                            \n",
      "         save_latest_freq: 2000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "              train_split: train                         \n",
      "                val_split: val                           \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions().parse(args=global_args)\n",
    "opt.dataroot = '{}/{}/'.format(opt.dataroot, opt.train_split)\n",
    "val_opt = get_val_opt(args=global_args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training images = 300\n"
     ]
    }
   ],
   "source": [
    "data_loader = create_dataloader(opt)\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\ruixu33/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0.00/97.8M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fe12deb857f4afd9caab71bc3eee92a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Trainer(opt)\n",
    "early_stopping = EarlyStopping(patience=opt.earlystop_epoch, delta=-0.001, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 0, iters 300\n",
      "(Val @ epoch 0) acc: 0.845; ap: 0.956787515515377\n",
      "Validation accuracy increased (-inf --> 0.845000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:39<2:43:30, 99.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19211924076080322 at step: 400\n",
      "(Val @ epoch 1) acc: 0.88; ap: 0.9759899503911874\n",
      "Validation accuracy increased (0.845000 --> 0.880000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:47<2:12:29, 81.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3984913229942322 at step: 800\n",
      "(Val @ epoch 2) acc: 0.895; ap: 0.9819864254596968\n",
      "Validation accuracy increased (0.880000 --> 0.895000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [03:55<2:01:24, 75.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15169614553451538 at step: 1200\n",
      "(Val @ epoch 3) acc: 0.9375; ap: 0.9913954431277919\n",
      "Validation accuracy increased (0.895000 --> 0.937500).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [06:09<1:50:44, 69.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 4) acc: 0.9191666666666667; ap: 0.9896905318030185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.11843067407608032 at step: 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [07:15<1:47:25, 68.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 5) acc: 0.9333333333333333; ap: 0.9925719557663335\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.08635769039392471 at step: 2000\n",
      "saving the latest model cs4487_proj_submission (epoch 6, model.total_steps 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [08:21<1:45:14, 67.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 6) acc: 0.9383333333333334; ap: 0.9938640152852265\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Train loss: 0.082588791847229 at step: 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [09:27<1:43:04, 67.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 7) acc: 0.9275; ap: 0.989362527016792\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [10:33<1:41:12, 66.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 8) acc: 0.8883333333333333; ap: 0.9860033321949444\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Learning rate dropped by 10, continue training...\n",
      "Train loss: 0.060043781995773315 at step: 2800\n",
      "(Val @ epoch 9) acc: 0.9741666666666666; ap: 0.9975337303639611\n",
      "Validation accuracy increased (-inf --> 0.974167).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [11:39<1:39:49, 66.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.006598228123039007 at step: 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [12:45<1:38:24, 66.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 10) acc: 0.9733333333333334; ap: 0.9978439353954258\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.005564074497669935 at step: 3600\n",
      "(Val @ epoch 11) acc: 0.9766666666666667; ap: 0.9978606478869669\n",
      "Validation accuracy increased (0.974167 --> 0.976667).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [14:59<1:37:11, 67.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 12) acc: 0.9758333333333333; ap: 0.9981687832155313\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.018061770126223564 at step: 4000\n",
      "saving the latest model cs4487_proj_submission (epoch 13, model.total_steps 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [16:08<1:36:55, 67.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 13) acc: 0.9725; ap: 0.9980528381245479\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.015072602778673172 at step: 4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [17:14<1:35:04, 67.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 14) acc: 0.9716666666666667; ap: 0.9978878729667342\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Train loss: 0.000979141565039754 at step: 4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [18:20<1:33:29, 66.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 15) acc: 0.9766666666666667; ap: 0.9983501399902499\n",
      "EarlyStopping counter: 4 out of 5\n",
      "(Val @ epoch 16) acc: 0.9791666666666666; ap: 0.9984167996109232\n",
      "Validation accuracy increased (0.976667 --> 0.979167).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [19:27<1:32:05, 66.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.005524624139070511 at step: 5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [20:32<1:30:34, 66.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 17) acc: 0.98; ap: 0.9985232307322377\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.002129620872437954 at step: 5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [21:38<1:29:17, 66.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 18) acc: 0.9758333333333333; ap: 0.9981909865467113\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.001240927493199706 at step: 6000\n",
      "saving the latest model cs4487_proj_submission (epoch 19, model.total_steps 6000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [22:44<1:28:14, 66.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 19) acc: 0.975; ap: 0.9983303342371747\n",
      "EarlyStopping counter: 3 out of 5\n",
      "saving the model at the end of epoch 20, iters 6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [23:51<1:27:28, 66.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 20) acc: 0.975; ap: 0.9983185038464688\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Train loss: 0.003544930135831237 at step: 6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [24:58<1:26:29, 66.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 21) acc: 0.9758333333333333; ap: 0.9985285731581867\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Learning rate dropped by 10, continue training...\n",
      "Train loss: 0.0014800552744418383 at step: 6800\n",
      "(Val @ epoch 22) acc: 0.9783333333333334; ap: 0.9986803181178576\n",
      "Validation accuracy increased (-inf --> 0.978333).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [26:04<1:25:06, 66.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.028135843575000763 at step: 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [27:09<1:23:45, 66.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 23) acc: 0.9775; ap: 0.9986497521544822\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [28:16<1:22:59, 66.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 24) acc: 0.9791666666666666; ap: 0.9984610858903711\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.0023997509852051735 at step: 7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [29:23<1:21:51, 66.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 25) acc: 0.9791666666666666; ap: 0.9984255542678524\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Train loss: 0.00020597621914930642 at step: 8000\n",
      "saving the latest model cs4487_proj_submission (epoch 26, model.total_steps 8000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [30:29<1:20:30, 66.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 26) acc: 0.9791666666666666; ap: 0.9984187387605362\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Train loss: 0.0018357132794335485 at step: 8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [31:34<1:25:23, 70.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Val @ epoch 27) acc: 0.9791666666666666; ap: 0.9985645392558612\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for epoch in tqdm(range(opt.niter)): # 100\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        model.total_steps += 1\n",
    "        epoch_iter += opt.batch_size\n",
    "\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if model.total_steps % opt.loss_freq == 0:\n",
    "            print(\"Train loss: {} at step: {}\".format(model.loss, model.total_steps))\n",
    "\n",
    "        if model.total_steps % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model %s (epoch %d, model.total_steps %d)' %\n",
    "                  (opt.name, epoch, model.total_steps))\n",
    "            model.save_networks('latest')\n",
    "\n",
    "        # print(\"Iter time: %d sec\" % (time.time()-iter_data_time))\n",
    "        # iter_data_time = time.time()\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\n",
    "              (epoch, model.total_steps))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    acc, ap = validate(model.model, val_opt)[:2]\n",
    "    print(\"(Val @ epoch {}) acc: {}; ap: {}\".format(epoch, acc, ap))\n",
    "\n",
    "    early_stopping(acc, model)\n",
    "    if early_stopping.early_stop:\n",
    "        cont_train = model.adjust_learning_rate()\n",
    "        if cont_train:\n",
    "            print(\"Learning rate dropped by 10, continue training...\")\n",
    "            early_stopping = EarlyStopping(patience=opt.earlystop_epoch, delta=-0.002, verbose=True)\n",
    "        else:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "    model.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "test_args = [\n",
    "    \"--batch_size\", \"32\", # default=64\n",
    "    \"--model_path\", \"./checkpoints/cs4487_proj_submission/model_epoch_best.pth\",\n",
    "    \"--dir\", \"./dataset/test\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not cropping\n",
      "Loading [1] datasets\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('-d','--dir', nargs='+', type=str, default='examples/realfakedir')\n",
    "parser.add_argument('-m','--model_path', type=str, default='weights/blur_jpg_prob0.5.pth')\n",
    "parser.add_argument('-b','--batch_size', type=int, default=32)\n",
    "parser.add_argument('-j','--workers', type=int, default=4, help='number of workers')\n",
    "parser.add_argument('-c','--crop', type=int, default=None, help='by default, do not crop. specify crop size')\n",
    "parser.add_argument('--use_cpu', action='store_true', help='uses gpu by default, turn on to use cpu')\n",
    "parser.add_argument('--size_only', action='store_true', help='only look at sizes of images in dataset')\n",
    "\n",
    "opt = parser.parse_args(test_args)\n",
    "\n",
    "# Load model\n",
    "if(not opt.size_only):\n",
    "    model = resnet50(num_classes=1)\n",
    "    if(opt.model_path is not None):\n",
    "        state_dict = torch.load(opt.model_path, map_location='cpu')\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    model.eval()\n",
    "    if(not opt.use_cpu):\n",
    "        model.cuda()\n",
    "\n",
    "# Transform\n",
    "trans_init = []\n",
    "if(opt.crop is not None):\n",
    "    trans_init = [transforms.CenterCrop(opt.crop),]\n",
    "    print('Cropping to [%i]'%opt.crop)\n",
    "else:\n",
    "    print('Not cropping')\n",
    "trans = transforms.Compose(trans_init + [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset loader\n",
    "if(type(opt.dir)==str):\n",
    "    opt.dir = [opt.dir,]\n",
    "\n",
    "print('Loading [%i] datasets' % len(opt.dir))\n",
    "data_loaders = []\n",
    "for dir in opt.dir:\n",
    "    dataset = datasets.ImageFolder(dir, transform=trans)\n",
    "    data_loaders+=[torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=opt.batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=opt.workers),]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:04<00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num reals: 392, Num fakes: 808\n",
      "Accuracy: 97.08, Recall: 96.94, Precision: 94.29, AUC: 99.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "Hs, Ws = [], []\n",
    "with torch.no_grad():\n",
    "    for data_loader in data_loaders:\n",
    "        for data, label in tqdm(data_loader):\n",
    "            Hs.append(data.shape[2])\n",
    "            Ws.append(data.shape[3])\n",
    "\n",
    "            y_true.extend(label.flatten().tolist())\n",
    "            if(not opt.size_only):\n",
    "                if(not opt.use_cpu):\n",
    "                    data = data.cuda()\n",
    "            y_pred.extend(model(data).sigmoid().flatten().tolist())\n",
    "\n",
    "Hs, Ws = np.array(Hs), np.array(Ws)\n",
    "y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# print('Average sizes: [{:2.2f}+/-{:2.2f}] x [{:2.2f}+/-{:2.2f}] = [{:2.2f}+/-{:2.2f} Mpix]'.format(np.mean(Hs), np.std(Hs), np.mean(Ws), np.std(Ws), np.mean(Hs*Ws)/1e6, np.std(Hs*Ws)/1e6))\n",
    "print('Num reals: {}, Num fakes: {}'.format(np.sum(1-y_true), np.sum(y_true)))\n",
    "\n",
    "if(not opt.size_only):\n",
    "    TP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    FP = []\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_true[i] == 0):\n",
    "            if (y_pred[i] > 0.5):\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TP.append(i)\n",
    "        else:\n",
    "            if (y_pred[i] > 0.5):\n",
    "                TN.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "    # r_acc = accuracy_score(y_true[y_true==0], y_pred[y_true==0] > 0.5) # TP / T\n",
    "    # f_acc = accuracy_score(y_true[y_true==1], y_pred[y_true==1] > 0.5) # FN / F\n",
    "    acc = (len(TP) + len(TN)) / (len(TP) + len(TN) + len(FP) + len(FN))\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    recall = len(TP) / (len(TP) + len(FN))\n",
    "    precision = len(TP) / (len(TP) + len(FP))\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    print('Accuracy: {:2.2f}, Recall: {:2.2f}, Precision: {:2.2f}, AUC: {:2.2f}'.format(acc*100., recall*100., precision*100., auc*100.))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
